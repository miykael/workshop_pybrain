{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVPA and Searchlight with `nilearn`\n",
    "\n",
    "In this section we will show how you can use `nilearn` to perform multivariate pattern analysis (MVPA), either in a specific region of interest (ROI) or directly in the whole brain, for example with a Searchlight analysis.\n",
    "\n",
    "\n",
    "## `nilearn`\n",
    "\n",
    "Although nilearn's visualizations are quite nice, its primary purpose was to facilitate machine learning in neuroimaging. It's in some sense the bridge between [nibabel](http://nipy.org/nibabel/) and [scikit-learn](http://scikit-learn.org/stable/). On the one hand, it reformats images to be easily passed to scikit-learn, and on the other, it reformats the results to produce valid nibabel images.\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<h3>Disclaimer</h3>\n",
    "<b>First</b>: This section is heavily based on the <a href=\"https://nilearn.github.io/decoding/index.html\">nilearn tutorials</a>.\n",
    "    \n",
    "<b>Second</b>: This section is not intended to teach machine learning, but to demonstrate a simple nilearn pipeline.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import pandas as pd\n",
    "from nilearn.image import resample_to_img, math_img, mean_img\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locating and verifying the machine learning dataset\n",
    "First, let's verify the location and size of the dataset we prepared in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = '/home/neuro/workshop/notebooks/data/dataset_ML.nii.gz'\n",
    "!nib-ls $func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For quicker access, let's also create a functional mean image\n",
    "img_mean = mean_img(func)\n",
    "img_mean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating masks\n",
    "\n",
    "Now, let's create multiple masks to better restrict some of our analysis. What we'll need is a mask for the brain (and in this case exceptionally also the eyes), as well as a mask for three different regions of interests (ROI): The primary visual cortex (V1), the primary audiotry cortex (A1) and the eyes (EYE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(img_roi, img_mean):\n",
    "    \n",
    "    # Resample mask to functional space\n",
    "    img_resampled = resample_to_img(img_roi, img_mean)\n",
    "\n",
    "    # Binarize ROI template\n",
    "    data_binary = np.array(img_resampled.get_fdata()!=0, dtype=np.int8)\n",
    "\n",
    "    # Dilate binary mask once\n",
    "    data_dilated = binary_dilation(data_binary, iterations=1).astype(np.int8)\n",
    "\n",
    "    # Save binary mask in NIfTI image\n",
    "    mask = nb.Nifti1Image(data_dilated, img_resampled.affine, img_resampled.header)\n",
    "    \n",
    "    # Restrict mask only to voxels with functional values\n",
    "    mask = math_img(\"(mean * mask)>0\", mean=img_mean, mask=mask)\n",
    "    mask.set_data_dtype('i1')\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're ready, let's create some masks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create global mask containing brain and eyes\n",
    "brain = '/home/neuro/workshop/notebooks/data/templates/MNI152_T1_1mm_brain.nii.gz'\n",
    "eyes = '/home/neuro/workshop/notebooks/data/templates/MNI152_T1_1mm_eye.nii.gz'\n",
    "img_roi = math_img(\"(img1 + img2)>0\", img1=brain, img2=eyes)\n",
    "img_resampled = resample_to_img(img_roi, img_mean)\n",
    "mask_global = math_img(\"((mean!=0)*img)>0.5\", mean=img_mean, img=img_resampled)\n",
    "\n",
    "# Plotting global mask\n",
    "anat = '/home/neuro/workshop/notebooks/data/templates/MNI152_T1_1mm.nii.gz'\n",
    "plot_roi(mask_global, img_mean, cmap='Paired', dim=-.5, draw_cross=False, annotate=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create eye mask containing both eyes\n",
    "img_roi = math_img(\"img>0\", img=eyes)\n",
    "img_resampled = resample_to_img(img_roi, img_mean)\n",
    "mask_eye = math_img(\"((mean!=0)*img)>0.5\", mean=img_mean, img=img_resampled)\n",
    "\n",
    "# Plotting global mask\n",
    "anat = '/home/neuro/workshop/notebooks/data/templates/MNI152_T1_1mm.nii.gz'\n",
    "plot_roi(mask_eye, img_mean, cmap='Paired', dim=-.5, draw_cross=False, annotate=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get region specific masks for V1 and A1, we will use [FSL's Harvard-Oxford atlas](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Atlases) as provided by [AtlasReader](https://github.com/miykael/atlasreader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels from AtlasReader\n",
    "atlas_path = '/opt/miniconda-latest/envs/neuro/lib/python3.7/site-packages/atlasreader/data/atlases/'\n",
    "atlas_labels = pd.read_csv(atlas_path + 'labels_harvard_oxford.csv', index_col=0)\n",
    "atlas_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load atlas from AtlasReader\n",
    "img_atlas = nb.load(atlas_path + 'atlas_harvard_oxford.nii.gz')\n",
    "img_atlas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load V1 ROI labels\n",
    "idx_v1 = [92, 93, 94, 95]\n",
    "display(atlas_labels.iloc[idx_v1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create V1 mask\n",
    "roi_v1 = mean_img([img_atlas.slicer[..., v] for v in idx_v1])\n",
    "img_roi = math_img(\"img>0\", img=roi_v1)\n",
    "img_resampled = resample_to_img(img_roi, img_mean)\n",
    "mask_v1 = math_img(\"((mean!=0)*img)>0.5\", mean=img_mean, img=img_resampled)\n",
    "\n",
    "# Plotting V1 mask\n",
    "plot_roi(mask_v1, img_mean, cmap='Paired', dim=-.5, draw_cross=False, annotate=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load A1 ROI labels\n",
    "idx_a1 = [88, 89, 90, 91]\n",
    "display(atlas_labels.iloc[idx_a1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create A1 mask\n",
    "roi_a1 = mean_img([img_atlas.slicer[..., a] for a in idx_a1])\n",
    "img_roi = math_img(\"img>0\", img=roi_a1)\n",
    "img_resampled = resample_to_img(img_roi, img_mean)\n",
    "mask_a1 = math_img(\"((mean!=0)*img)>0.5\", mean=img_mean, img=img_resampled)\n",
    "\n",
    "# Plotting V1 mask\n",
    "plot_roi(mask_a1, img_mean, cmap='Paired', dim=-.5, draw_cross=False, annotate=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels and chunks\n",
    "\n",
    "Now that we have the dataset and the masks at hand, we're almost ready for some machine learning. Only thing still missing are the **target labels** (i.e. which samples / time-points are \"eyes open\" condition and which ones aren't, and **chunks/subject_identifier** to prevent data leakage between model training and validation.\n",
    "\n",
    "From the last section of the [Machine Learning Preparation](machine_learning_preparation.ipynb) notebook, we know that we have a total of 384 volumes in our `dataset_ML.nii.gz` file and that it's always 4 volumes of the condition `eyes closed`, followed by 4 volumes of the condition `eyes open`, etc. Therefore our labels should be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.ravel([[['closed'] * 4, ['open'] * 4] for i in range(48)])\n",
    "labels[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, the `chunks` variable is important if we want to do for example something like cross-validation. In our case we would ideally create 48 chunks, one for each subject. But because a cross-validation of 48 chunks takes very long, let's just create 6 chunks, containing always 8 subjects, i.e. 64 volumes in one group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = np.ravel([[i] * 64 for i in range(6)])\n",
    "chunks[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to do cross-validation is the so called **Leave-one-out cross-validation**. This approach trains on `(n - 1)` chunks, and classifies the remaining chunk, and repeats this for every chunk, also called **fold**. Therefore, a 6-fold cross-validation is one that divides the whole data into 6 different chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI-based decoding analysis\n",
    "\n",
    "Now that the masks are ready, let's look at a ROI based decoding analysis. In other words, we'll use the response patterns of voxels in the mask to predict if the eyes were **closed** or **open** during a resting-state fMRI recording.\n",
    "\n",
    "To setup the procedure let's perform the analysis first just for the **ROI of V1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2use = mask_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking and Un-masking data\n",
    "\n",
    "For the classification with `nilearn`, we need our functional data in a 2D, sample-by-voxel matrix. To get that, we'll select all the voxels within our `mask`. To do this, we can use the `NiftiMasker` object, which applies a mask to a dataset and returns the masked voxels flattened to a 2D matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask ML dataset with V1 ROI mask\n",
    "from nilearn.input_data import NiftiMasker\n",
    "masker = NiftiMasker(mask_img=mask2use, standardize=False, detrend=False,\n",
    "                     memory=\"nilearn_cache\", memory_level=2)\n",
    "samples = masker.fit_transform(func)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its shape corresponds to the number of time-points times the number of voxels in the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recover the original data shape (giving us a masked and z-scored BOLD series), we simply use the masker's inverse transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_epi = masker.inverse_transform(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now visualize the masked epi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map\n",
    "\n",
    "max_zscores = math_img(\"np.abs(img).max(axis=3)\", img=masked_epi)\n",
    "plot_stat_map(max_zscores, bg_img=anat, dim=-.5,\n",
    "              draw_cross=False, annotate=False, colorbar=False,\n",
    "              title='Maximum Amplitude per Voxel in Mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split of dataset\n",
    "\n",
    "To be able to test how well our model performs, we need to a test set, i.e. a dataset that wasn't used to train the model. The easiest solution to this is to use scikit-learns `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_v1, X_test_v1, y_train_v1, y_test_v1, c_train, c_test = train_test_split(\n",
    "    samples, labels=='open', chunks, test_size=64, random_state=0, shuffle=False)\n",
    "\n",
    "print('Shapes of X:', X_train_v1.shape, X_test_v1.shape)\n",
    "print('Shapes of y:', y_train_v1.shape, y_test_v1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing a linear support vector machine (linear SVC) model for V1 ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', LinearSVC(multi_class='ovr', penalty='l2',\n",
    "                      loss='squared_hinge', max_iter=500))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter grid to be explored during grid search\n",
    "grid = {\n",
    "    'svc__C': np.logspace(-6, 2, num=40),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search object with a cross-validation with LeaveOneGroupOut\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "grid_cv_v1 = GridSearchCV(pipe, grid, cv=LeaveOneGroupOut(),\n",
    "                          return_train_score=True, refit=True, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and find optimal hyperparameter\n",
    "grid_cv_v1.fit(X=X_train_v1, y=y_train_v1, groups=c_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand the model performance during the hyperparamter fine tuning, let's write a supportive plotting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hyperparam_fitting(cv_results):\n",
    "\n",
    "    # Store grid search parameters and outcomes in dataframe\n",
    "    df_pred = pd.DataFrame(cv_results)\n",
    "    columns = [c for c in df_pred.columns if 'time' not in c\n",
    "               and 'split' not in c\n",
    "               and 'rank' not in c\n",
    "               and c!='params']\n",
    "    df_pred = df_pred[columns].sort_values('mean_test_score', ascending=False)\n",
    "    display(df_pred.head())\n",
    "    \n",
    "    # Plot the model fit information\n",
    "    df_plot = df_pred.sort_values('param_svc__C')\n",
    "\n",
    "    # Exsract relevant modelling metrics\n",
    "    train_scores = df_plot['mean_train_score']\n",
    "    valid_scores = df_plot['mean_test_score']\n",
    "    std_tr = df_plot['std_train_score']\n",
    "    std_va = df_plot['std_test_score']\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    Cs = df_plot['param_svc__C']\n",
    "    plt.semilogx(Cs, train_scores, label='Training Set')\n",
    "    plt.semilogx(Cs, valid_scores, label='Validation Set')\n",
    "\n",
    "    # Add marker and text for best score\n",
    "    max_id = np.argmax(valid_scores)\n",
    "    x_pos = Cs.iloc[max_id]\n",
    "    y_pos = valid_scores.iloc[max_id]\n",
    "    txt = '{:0.4f}'.format(y_pos)\n",
    "    plt.scatter(x_pos, y_pos, marker='x', c='red', zorder=10)\n",
    "    plt.text(x_pos, y_pos, txt, fontdict={'size': 18})\n",
    "\n",
    "    # Quantify variance with Â±std curves\n",
    "    plt.fill_between(Cs.astype(float), train_scores-std_tr, train_scores+std_tr, alpha=0.3)\n",
    "    plt.fill_between(Cs.astype(float), valid_scores-std_va, valid_scores+std_va, alpha=0.3)\n",
    "    plt.ylabel('Performance metric')\n",
    "    plt.xlabel('Model parameter')\n",
    "\n",
    "    # Adjust x-lim, y-lim, add legend and adjust layout\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot hyperparameter fine tuning outcome\n",
    "plot_hyperparam_fitting(grid_cv_v1.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained and we've verified that the fit seems reasonable, let's compute the models performance on the withheld test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test_v1 = grid_cv_v1.score(X_test_v1, y_test_v1)\n",
    "print('Test score based on V1:', score_test_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the chance level is 50%, having ~73% accuracy on predicting if a person has eyes opened or closed during a resting state recording, only based on V1 information is rather good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing a linear support vector machine (linear SVC) model for A1 ROI\n",
    "\n",
    "What about the **regions A1**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask ML dataset with A1 ROI mask\n",
    "mask2use = mask_a1\n",
    "masker = NiftiMasker(mask_img=mask2use, standardize=False, detrend=False,\n",
    "                     memory=\"nilearn_cache\", memory_level=2)\n",
    "samples = masker.fit_transform(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train_a1, X_test_a1, y_train_a1, y_test_a1, c_train, c_test = train_test_split(\n",
    "    samples, labels=='open', chunks, test_size=64, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search object with a cross-validation with LeaveOneGroupOut\n",
    "grid_cv_a1 = GridSearchCV(pipe, grid, cv=LeaveOneGroupOut(),\n",
    "                          return_train_score=True, refit=True, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and find optimal hyperparameter\n",
    "grid_cv_a1.fit(X=X_train_a1, y=y_train_a1, groups=c_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot hyperparameter fine tuning outcome\n",
    "plot_hyperparam_fitting(grid_cv_a1.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test_a1 = grid_cv_a1.score(X_test_a1, y_test_a1)\n",
    "print('Test score based on A1:', score_test_a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below chance level,... It makes sense that A1 would be somewhere around chance level, but this value is nonetheless a bit low. Let's come back to this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing a linear support vector machine (linear SVC) model for eye ROI\n",
    "\n",
    "Let's also check an obvious region to detect if eyes were opened or closed, the **eyes themselves**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask ML dataset with eye ROI mask\n",
    "mask2use = mask_eye\n",
    "masker = NiftiMasker(mask_img=mask2use, standardize=False, detrend=False,\n",
    "                     memory=\"nilearn_cache\", memory_level=2)\n",
    "samples = masker.fit_transform(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train_eye, X_test_eye, y_train_eye, y_test_eye, c_train, c_test = train_test_split(\n",
    "    samples, labels=='open', chunks, test_size=64, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search object with a cross-validation with LeaveOneGroupOut\n",
    "grid_cv_eye = GridSearchCV(pipe, grid, cv=LeaveOneGroupOut(),\n",
    "                           return_train_score=True, refit=True, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and find optimal hyperparameter\n",
    "grid_cv_eye.fit(X=X_train_eye, y=y_train_eye, groups=c_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot hyperparameter fine tuning outcome\n",
    "plot_hyperparam_fitting(grid_cv_eye.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test_eye = grid_cv_eye.score(X_test_eye, y_test_eye)\n",
    "print('Test score based on A1:', score_test_eye)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a very high score. Then again, not surprising for the eyes themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion of the ROI-based decoding analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame([0.5, score_test_v1, score_test_a1, score_test_eye],\n",
    "                      columns=['Accuracy'], index=['chance', 'V1', 'A1', 'eyes']).T.round(2)*100\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.bar(df_res.columns, df_res.values.T.ravel())\n",
    "plt.title('Decoding accuarcy for certain ROI');\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking one of the two classes \"eyes-closed\" or \"eyes-open\" would lead to a prediction accuracy of 50%, i.e. chance-level. Not surprisingly, the signal recorded within the eyes lead to the highest prediction accuracy, followed by the primary visual cortex, while the hopefully unrelated primary auditory cortex doesn't provide better prediction accuracy then the chance-level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation testing\n",
    "\n",
    "The approach above, with using a train and test set is important in machine learning to establish an optimized model and to judge how well it can generalize to a new dataset (here the test set).\n",
    "\n",
    "One way to test the quality of the prediction accuracy is to run the cross-validation multiple times, but permutate the labels of the volumes randomly. Afterward we can compare the accuracy value of the correct labels to the ones with the random / false labels. Luckily `Scikit-learn` already has a function that does this for us. So let's do it.\n",
    "\n",
    "**Note**: As a classifier, we will chose the best classifier/estimator from our grid search above. Additionally, we chose the number of iterations under `n_permutations` for the permutation testing rather low, to reduce computation time as well. This value should ideally be higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permuation testing for V1-ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import permutation_test_score\n",
    "\n",
    "# Mask ML dataset with v1 ROI mask\n",
    "mask2use = mask_v1\n",
    "masker = NiftiMasker(mask_img=mask2use, standardize=False, detrend=False,\n",
    "                     memory=\"nilearn_cache\", memory_level=2)\n",
    "samples = masker.fit_transform(func)\n",
    "\n",
    "# Get best classifier from gridsearch\n",
    "clf = grid_cv_v1.best_estimator_\n",
    "\n",
    "# Run the permuation cross-validation\n",
    "null_cv_scores = permutation_test_score(estimator=clf,\n",
    "                                        X=samples,\n",
    "                                        y=labels,\n",
    "                                        groups=chunks,\n",
    "                                        cv=LeaveOneGroupOut(),\n",
    "                                        n_permutations=200,\n",
    "                                        n_jobs=-1,\n",
    "                                        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's take a look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the null distribution\n",
    "plt.title('Null-hypothesis prediction accuracy')\n",
    "plt.hist(null_cv_scores[1], bins=25, density=True);\n",
    "plt.vlines(null_cv_scores[0], 0, 25, color='r')\n",
    "print('Red line indicates accuracy of actual labels.')\n",
    "\n",
    "print('Prediction accuracy: %.02f' % (null_cv_scores[0] * 100),\n",
    "      'p-value: %.04f' % (null_cv_scores[2]),\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! This means... Using resting-state fMRI images, we can predict if a person had their eyes open or closed with an accuracy significantly above chance level, when we only look at the activation from V1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permuation testing for A1-ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import permutation_test_score\n",
    "\n",
    "# Mask ML dataset with a1 ROI mask\n",
    "mask2use = mask_a1\n",
    "masker = NiftiMasker(mask_img=mask2use, standardize=False, detrend=False,\n",
    "                     memory=\"nilearn_cache\", memory_level=2)\n",
    "samples = masker.fit_transform(func)\n",
    "\n",
    "# Get best classifier from gridsearch\n",
    "clf = grid_cv_a1.best_estimator_\n",
    "\n",
    "# Run the permuation cross-validation\n",
    "null_cv_scores = permutation_test_score(estimator=clf,\n",
    "                                        X=samples,\n",
    "                                        y=labels,\n",
    "                                        groups=chunks,\n",
    "                                        cv=LeaveOneGroupOut(),\n",
    "                                        n_permutations=200,\n",
    "                                        n_jobs=-1,\n",
    "                                        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's take a look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the null distribution\n",
    "plt.title('Null-hypothesis prediction accuracy')\n",
    "plt.hist(null_cv_scores[1], bins=25, density=True);\n",
    "plt.vlines(null_cv_scores[0], 0, 25, color='r')\n",
    "print('Red line indicates accuracy of actual labels.')\n",
    "\n",
    "print('Prediction accuracy: %.02f' % (null_cv_scores[0] * 100),\n",
    "      'p-value: %.04f' % (null_cv_scores[2]),\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already seen before, using A1 to decode if somebody had eyes open or closed during the resting state recording doesn't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permuation testing for EYE-ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import permutation_test_score\n",
    "\n",
    "# Mask ML dataset with eye ROI mask\n",
    "mask2use = mask_eye\n",
    "masker = NiftiMasker(mask_img=mask2use, standardize=False, detrend=False,\n",
    "                     memory=\"nilearn_cache\", memory_level=2)\n",
    "samples = masker.fit_transform(func)\n",
    "\n",
    "# Get best classifier from gridsearch\n",
    "clf = grid_cv_eye.best_estimator_\n",
    "\n",
    "# Run the permuation cross-validation\n",
    "null_cv_scores = permutation_test_score(estimator=clf,\n",
    "                                        X=samples,\n",
    "                                        y=labels,\n",
    "                                        groups=chunks,\n",
    "                                        cv=LeaveOneGroupOut(),\n",
    "                                        n_permutations=200,\n",
    "                                        n_jobs=-1,\n",
    "                                        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's take a look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the null distribution\n",
    "plt.title('Null-hypothesis prediction accuracy')\n",
    "plt.hist(null_cv_scores[1], bins=25, density=True);\n",
    "plt.vlines(null_cv_scores[0], 0, 25, color='r')\n",
    "print('Red line indicates accuracy of actual labels.')\n",
    "\n",
    "print('Prediction accuracy: %.02f' % (null_cv_scores[0] * 100),\n",
    "      'p-value: %.04f' % (null_cv_scores[2]),\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also here, the previous assumption gets supported. The eyes are of course a very good location to predict if a participant had eyes open or closed during a resting state recording."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which region is driving the classification when we don't have prior knowledge?\n",
    "\n",
    "In the previous example, we had some intuition/hypothesis which regions to look into. But this might not always be the case. So how can we get some ideas about which regions might be driving the classification accuracy, when one is looking at the whole brain?\n",
    "\n",
    "There are many different ways to figure out which region is important for classification, but let us introduce you to two different approaches that you can use in `nilearn`: `SpaceNet` and  `Searchlight`\n",
    "\n",
    "**Note:** For both of these examples we will take the full brain mask prepared above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roi(mask_global, img_mean, cmap='Paired', dim=-.5, draw_cross=False, annotate=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpaceNet: decoding with spatial structure for better maps\n",
    "\n",
    "SpaceNet implements spatial penalties which improve brain decoding power as well as decoder maps. The results are brain maps which are both sparse (i.e regression coefficients are zero everywhere, except at predictive voxels) and structured (blobby). For more detail, check out `nilearn`'s section about [SpaceNet](http://nilearn.github.io/decoding/space_net.html).\n",
    "\n",
    "To train a SpaceNet on our data, let's first split the data into a training set (chunk 0-4) and a test set (chunk 5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "idx_train, idx_test, y_train, y_test, c_train, c_test = train_test_split(\n",
    "    range(len(samples)), labels=='open', chunks, test_size=64, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the NIfTI image into train and test set\n",
    "from nilearn.image import index_img\n",
    "X_train = index_img(func, idx_train)\n",
    "X_test = index_img(func, idx_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the SpaceNet to our data with a TV-l1 penalty. ***Note*** again, that we reduced the number of `max_iter` to have a quick computation. In a realistic case this value should be around 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.decoding import SpaceNetClassifier\n",
    "\n",
    "# Fit model on train data and predict on test data\n",
    "decoder = SpaceNetClassifier(penalty='tv-l1',\n",
    "                             mask=mask_global,\n",
    "                             max_iter=10,\n",
    "                             cv=5,\n",
    "                             standardize=True,\n",
    "                             memory=\"nilearn_cache\",\n",
    "                             memory_level=2,\n",
    "                             verbose=0)\n",
    "\n",
    "decoder.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the `SpaceNet` is fitted to the training data. Let's see how well it does in predicting the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test data\n",
    "y_pred = decoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrun average accuracy\n",
    "accuracy = (y_pred == y_test).mean() * 100.\n",
    "print(\"\\nTV-l1  classification accuracy : %g%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again above 80% prediction accuracy? But we wanted to know what's driving this prediction. So let's take a look at the fitting coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map, show\n",
    "coef_img = decoder.coef_img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the searchlight results on the glass brain\n",
    "from nilearn.plotting import plot_glass_brain\n",
    "plot_glass_brain(coef_img, black_bg=True, colorbar=True, display_mode='lyrz', symmetric_cbar=False,\n",
    "                 cmap='magma', title='graph-net: accuracy %g%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! As expected the visual cortex (in the back of the head) and the eyes are driving the classification!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searchlight: finding voxels containing information\n",
    "\n",
    "Now the next question is: How high would the prediction accuracy be if we only take one small region to do the classification?\n",
    "\n",
    "To answer this question we can use something that is called a **Searchlight** approach. The searchlight approach was first proposed by [Kriegeskorte et al., 2006](https://pdfs.semanticscholar.org/985c/ceaca8606443f9129616a26bbbbf952f2d7f.pdf). It is a widely used approach for the study of the fine-grained patterns of information in fMRI analysis. Its principle is relatively simple: a small group of neighboring features is extracted from the data, and the prediction function is instantiated on these features only. The resulting prediction accuracy is thus associated with all the features within the group, or only with the feature on the center. This yields a map of local fine-grained information, that can be used for assessing hypothesis on the local spatial layout of the neural code under investigation.\n",
    "\n",
    "You can do a searchlight analysis in `nilearn` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.decoding import SearchLight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the mask in which the searchlight should be performed\n",
    "mask = mask_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the classifier to use\n",
    "# For presentation purpose, let's use a GaussainNB classifier to have rather small computation time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the radius of the searchlight sphere  that will scan the volume\n",
    "# (the bigger the longer the computation)\n",
    "sphere_radius = 8  # in mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to create the searchlight object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create searchlight object\n",
    "sl = SearchLight(mask_global,\n",
    "                 process_mask_img=mask,\n",
    "                 radius=sphere_radius,\n",
    "                 estimator=clf,\n",
    "                 cv=LeaveOneGroupOut(),\n",
    "                 n_jobs=-1,\n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the searchlight algorithm\n",
    "sl.fit(nb.load(func), labels, groups=chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That took a while. So let's take a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to put the searchlight output back into an MRI image\n",
    "from nilearn.image import new_img_like\n",
    "searchlight_img = new_img_like(func, sl.scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the results. Let's plot it once on the glass brain and once from the side. For better interpretation on where the peaks are, let's set a minimum accuracy threshold of 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_glass_brain\n",
    "plot_glass_brain(searchlight_img, black_bg=True, colorbar=True, display_mode='lyrz',\n",
    "                 threshold=0.6, cmap='magma', title='Searchlight Prediction Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map\n",
    "plot_stat_map(searchlight_img, cmap='magma', bg_img=anat, colorbar=True,\n",
    "              display_mode='x', threshold=0.6, cut_coords=[0, 6, 12, 18],\n",
    "              title='Searchlight Prediction Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected and already seen before, the hotspots with high prediction accuracy are around the primary visual cortex (in the back of the head) and around the eyes."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
